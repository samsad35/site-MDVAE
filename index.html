<!DOCTYPE HTML>
<html>
	<head>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());

		  gtag('config', 'UA-109046767-2');
		</script>


		<!-- CHANGE HERE -->
		<title>A Multimodal Dynamical Variational Autoencoder for Audiovisual Speech Representation Learning</title>
		<!-- ----------- -->
		<script src="https://cdn.jsdelivr.net/npm/before-after-slider@1.0.0/dist/slider.bundle.js"></script>


		<script
		  defer
		  src="https://unpkg.com/img-comparison-slider@7/dist/index.js"
		></script>
		<link
		  rel="stylesheet"
		  href="https://unpkg.com/img-comparison-slider@7/dist/styles.css"
		/>

		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<link href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,300italic,600|Source+Code+Pro" rel="stylesheet" />
		<script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>
		<script src="js/jquery.dropotron.min.js"></script>
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.css" integrity="sha384-D+9gmBxUQogRLqvARvNLmA9hS2x//eK1FhVb9PiU86gmcrBrJAQT8okdJ4LMp2uv" crossorigin="anonymous">

		<!-- The loading of KaTeX is deferred to speed up page rendering -->
		<script src="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.js" integrity="sha384-483A6DwYfKeDa0Q52fJmxFXkcPCFfnXMoXblOkJ4JcA8zATN6Tm78UNL72AKk+0O" crossorigin="anonymous"></script>

		<!-- To automatically render math in text elements, include the auto-render extension: -->
		<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/contrib/auto-render.min.js" integrity="sha384-yACMu8JWxKzSp/C1YV86pzGiQ/l1YUfE8oPuahJQxzehAjEt2GiQuy/BIvl9KyeF" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
		<script src="js/skel.min.js">
		{
			prefix: 'css/style',
			preloadStyleSheets: true,
			resetCSS: true,
			boxModel: 'border',
			grid: { gutters: 30 },
			breakpoints: {
				wide: { range: '1200-', containers: 1140, grid: { gutters: 50 } },
				narrow: { range: '481-1199', containers: 960 },
				mobile: { range: '-480', containers: 'fluid', lockViewport: true, grid: { collapse: true } }
			}
		}
		</script>

		<style>
			table tr th, table tr td {
			text-align: center;
			vertical-align: middle;
			border: 0px solid white;
			border-collapse: collapse;
			}
		</style>

		<style type="text/css">a {text-decoration: none}</style>

	</head>

	<body>

		<div id="site_content">
		<div class="container">

		<!-- Features -->
		<div class="row">
			<section class="12u">

				<h2 style="text-align: center;">
					A Multimodal Dynamical Variational Autoencoder for Audiovisual Speech Representation Learning
				</h2>

				<p style="text-align: center;">
					Samir Sadok<sup>1</sup>&emsp;&emsp; Simon Leglaive<sup>1</sup>&emsp;&emsp; Laurent Girin<sup>2</sup>&emsp;&emsp; Xavier Alameda-Pineda<sup>3</sup>&emsp;&emsp; Renaud Séguier<sup>1</sup>&emsp;&emsp;
				</p>

				<p style="text-align: center; line-height: 100%;">
					<sup>1</sup>CentraleSupélec, IETR UMR CNRS 6164, France &emsp;&emsp; <br>
					<sup>2</sup>Univ. Grenoble Alpes, CNRS, Grenoble-INP, GIPSA-lab, France  &emsp;&emsp;<br>
					<sup>3</sup>Inria, Univ. Grenoble Alpes, CNRS, LJK, France<br>
				</p>
				<!--
				<p style="text-align: center;">
					Inproceedings
				</p> 
				-->

				<p style="text-align: center;">
					 <a href="https://arxiv.org/MDVAE" target="_blank" rel="noopener">Article</a> |
					<!-- <a href="#audio">Audio examples</a> |  -->
					 <a href="documents/presentation_icassp2020.pdf">Slides</a> |  
					<a href="https://github.com/samsad35/multimodal_vae" target="_blank" rel="noopener">Code</a> 
					<!-- <a href="https://hal.archives-ouvertes.fr/hal-03603791v1/bibtex" target="_blank" rel="noopener">Bibtex</a> | -->
					<!-- <a href="#acknowledgement">Acknowledgement</a> -->
				</p>

				<!-- Abstract -->
				<strong><span style="font-size: large;"><a name="abstract"></a>Abstract</span></strong>
				<hr>
				
				
				<div style="width:100%; text-align: center;">
					<img src="demos/MDVAE/graph.png" align="right" width="600" title="MDVAE’s graphical model in compact form"> 
				</div>
				<p style = "text-align: justify; vertical-align: top;"> Controlling and understanding the latent space of a multimodal generative model is a current challenge to perform analysis and to have a meaningful representation improving auxiliary tasks such as emotion classification. We have developed dynamical multimodal VAE (MDVAE), a double hierarchical generative model: at the temporal level (static and dynamical) and the modality level (specific and shared). This latent space disentanglement is adequate for very heterogeneous data where the temporal dimension is present. Trained on an audio-visual database, MDVAE can dissociate lip configuration from other visual information (such as eye movement) in different spaces. MDVAE can also separate static global information such as the physical description of the face or emotions from dynamical information such as the movement of the head or the eyes. We show that our method is generalizable to multimodal data other than audio-visual. </p>

				<!-- Phase reconstruction problem -->
				<span style="font-size: large;"><a name="phase_reconstruction"></a><strong>MDVAE: Multimodal Dynamical Variational Autoencoder</strong></span>
				<hr>
				<p style = "text-align: justify; vertical-align: top;">The VAE has been extended in many ways, including for dealing with data that are either multimodal or dynamical (i.e., sequential), but not both at the same time. This paper proposes an approach to combine these two extensions in order to process simultaneously multimodal data and sequential data (e.g., audio-visual data).
				To our knowledge, it is the first generative model that considers the inputs' multimodality and their dynamical aspects. Our goal is to have a hierarchical latent space, one in the temporal perspective to dissociate static information from dynamical information and another in the modality perspective to separate common information from specific information for each modality.
				</p>
				Two significant contributions are implemented in our studies:
				<ul>
				  <li> Representation of heterogeneous multimodal data by low-dimensional latent spaces learned in an unsupervised way: a latent dynamical space specific to each modality, taking into account temporal dependencies. Another latent dynamical space but this time shared by the modalities. And finally, a latent static space to encode the global and temporally independent information. Trained on an audio-visual database, we experimentally show that the MDVAE manages to dissociate the dynamical information from the global static information while factoring it into shared and modality-specific latent spaces. </li>
				  <li> Improvement of the data reconstruction quality by training MDVAE in two steps: the first step consists in learning VQ-VAE independently for each modality without the temporal aspect. Moreover, the second step consists in learning the MDVAE, whose inputs are the intermediate representations of the VQ-VAE before quantization. The temporal disentanglement and the modalities' disentanglement occur in this second stage.</li>
				</ul>
				
				<table>
					<td text-align: center;>
						<img src="demos/MDVAE/VQ-MDVAE.png" alt="VQ-MDVAE"  width="880" />
					</td>
					
					<td>
						<img src="demos/MDVAE/notations.PNG" alt="F1 subspace"  width="250" />
					</td>
				</table>

			<!-- VISUALISATION OF THE LEARNED LATENT SUBSPACES -->
			<span style="font-size: large;"><a name="latentspace"></a><strong>What is encoded in the latent spaces of the MDVAE?</strong></span>
			<hr>
			
			We will present qualitative results obtained by reconstructing an audiovisual speech sequence using some of the latent variables from another sequence.
			<br>
			<span style="font-size: medium; color:#757470;"><a name="Visual"></a><strong>For the visual modality:</strong></span>
			

			<div style="width:100%; text-align: center;">
			<table style="width:100%; text-align: center;">
					<td>
					<p> We transfer <span style="color:red">\(\mathbf{z}^{(v)}\) </span> from the central sequence in red to the surrounding sequences.</p>
						<img src="demos/Gifs/z_visual.gif" alt="z_v"  width="300" />
					<p> Only head and eye movements are transfered.</p>
					</td>
					
					<td>
					<p> We transfer <span style="color:green">\(\mathbf{z}^{(av)}\) </span> from the central sequence in red to the surrounding sequences.</p>
						<img src="demos/Gifs/z_av.gif" alt="z_v"  width="300" />
						<p> Only lip movements are transfered.</p>
					</td>
					
					<td>
					<p> We transfer <span style="color:red">\(\mathbf{z}^{(v)}\) </span> and <span style="color:green">\(\mathbf{z}^{(av)}\) </span> from the central sequence in red to the surrounding sequences.</p>
						<img src="demos/Gifs/gif-4.gif" alt="z_v"  width="300" />
						<p> All dynamical factors are transfered.</p>
					</td>
			</table>
			</div>

			<hr style="width:50%">


			<style type="text/css">
			  img-comparison-slider {
				--divider-width: 3px;
				--divider-color: #48C9B0;
				--default-handle-width: 80px;
				--default-handle-opacity: 1.0;
				--divider-shadow: 0px 0px 5px rgba(0, 0, 1, 0.5);
				--default-handle-color: #48C9B0;
			  }
			</style>

			<div style="width:100%; text-align: center;">
			<table style="width:100%; text-align: center;">
				<td>
					<p> Two original visual sequences. (Scroll left) the visual sequence of a man; (Scroll right) the visual sequence of a woman;  </p>
					<img-comparison-slider>
						<img class="source" slot="first" src="demos/sliders/images/2.png" width="100%"/>
						<img class="source" slot="second" src="demos/sliders/images/1.png" width="100%" />
					</img-comparison-slider>
				</td>
				<td>
			</table>
			</div>
			<style>
				img.target {
					filter: brightness(70%);
				}
			</style>

			<style>
				img.source {
				   filter: brightness(110%);
				}
			</style>
			<div style="width:100%; text-align: center;">
			<table style="width:100%; text-align: center;">
				<tr>
					<td>
						<p> We transfer <span style="color:red">\(\mathbf{z}^{(v)}\) </span> from the shadow sequence to the non-shadow sequence.  </p>
						<img-comparison-slider value="10">
							<img class="source" slot="first" src="demos/sliders/images/zv.png" width="100%"/>
							<img class="target" slot="second" src="demos/sliders/images/1.png" width="100%" />
						</img-comparison-slider>
					</td>
					<td>
						<p> We transfer <span style="color:green">\(\mathbf{z}^{(av)}\) </span> from the shadow sequence to the non-shadow sequence.  </p>
						<img-comparison-slider value="10">
							<img class="source" slot="first" src="demos/sliders/images/zav.png" width="100%"/>
							<img class="target" slot="second" src="demos/sliders/images/1.png" width="100%" />
						</img-comparison-slider>
					</td>
				</tr>

				<tr>
					<td>
						<img-comparison-slider value="10">
							<img class="source" slot="first" src="demos/sliders/images/zv-2.png" width="100%"/>
							<img class="target" slot="second" src="demos/sliders/images/2.png" width="100%" />
						</img-comparison-slider>
					</td>
					<td>
						<img-comparison-slider value="10">
							<img class="source" slot="first" src="demos/sliders/images/zav-2.png" width="100%"/>
							<img class="target" slot="second" src="demos/sliders/images/2.png" width="100%" />
						</img-comparison-slider>
					</td>
				</tr>
			</table>
			</div>

			<div style="width:100%; text-align: center;">
			<table style="width:100%; text-align: center;">
				<tr>
					<td>
						<p> We transfer <span style="color:red">\(\mathbf{z}^{(v)}\) </span> and <span style="color:green">\(\mathbf{z}^{(av)}\) </span> from the shadow sequence to the non-shadow sequence. </p>
						<img-comparison-slider value="10">
							<img class="source" slot="first" src="demos/sliders/images/zav-zv-2.png" width="100%"/>
							<img class="target" slot="second" src="demos/sliders/images/2.png" width="100%" />
						</img-comparison-slider>
					</td>
				</tr>
				<tr>
					<td>
						<img-comparison-slider value="10">
							<img class="source" slot="first" src="demos/sliders/images/zav-zv.png" width="100%"/>
							<img class="target" slot="second" src="demos/sliders/images/1.png" width="100%" />
						</img-comparison-slider>
					</td>
				</tr>

			</table>
			</div>


			<hr style="width:50%">
			In the annimation below, we transfer <span style="color:green">\(\mathbf{z}^{(av)}\) </span> and <span style="color:red">\(\mathbf{z}^{(v)}\) </span> from the central sequence in red to the surrounding sequences. The identity and global emotional state are preserved because \myw{}w is unaltered.
			<div style="width:100%; text-align: center;">
				<video controls autoplay  muted preload="auto" width="1000" height="700">
				  <source src="demos/Video/video-13.mp4" type="video/mp4">
				  <source src="demos/Video/video-13.ogg" type="video/ogg">
				  Your browser does not support the video tag.
				</video>
			</div>




			<br>
			<br>
			<span style="font-size: strong; color:#757470;"><a name="Audio"></a><strong>For the audio modality:</strong></span>
			<div style="width:100%; text-align: center;">
			<table style="width:100%; text-align: center;">
					<td>
						<p> <span style="color:blue">\(\mathbf{z}^{(a)}\) </span> and <span style="color:green">\(\mathbf{z}^{(av)}\) </span> are fixed, <span style="color:green">\(\mathbf{w}\)</span> varies.</p>
						<img src="demos/Gifs/vary_w.gif" alt="audio-w"  width="350" />
						<p> <span style="color:green">\(\mathbf{w}\)</span> seems to encode the speaker's audio identity. </p>
					</td>
					
					<td>
						<p> <span style="color:green">\(\mathbf{w}\)</span>  and <span style="color:green">\(\mathbf{z}^{(av)}\) </span> are fixed, <span style="color:blue">\(\mathbf{z}^{(a)}\) </span> varies.</p>
						<img src="demos/Gifs/vary_z_a.gif" alt="audio-za"  width="350" />
						<p> <span style="color:green">\(\mathbf{z}^{(v)}\) </span> encodes the high-frequency phonemic content.</p>
					</td>
					
					<td>
					<p> <span style="color:blue">\(\mathbf{z}^{(a)}\) </span> and <span style="color:green">\(\mathbf{w}\)</span> are fixed, <span style="color:green">\(\mathbf{z}^{(av)}\) </span> varies.</p>
						<img src="demos/Gifs/vary_z_ds.gif" alt="audio-zav"  width="350" />
						<p> <span style="color:green">\(\mathbf{z}^{(av)}\) </span> encodes the low-frequency phonemic content.</p>
					</td>
			</table>
			</div>

			<script>
				var za  = 1;
				var zav  = 1;
        		function myFunctionZa() {
				  za = Math.floor(Math.random()*100);
				  document.getElementById('za1').src="demos/generation/audio/zaudio-"+za+".png"
				  document.getElementById('za2').src="demos/generation/audio-2/zaudio-"+za+".png"
				}

				function myFunctionZav() {
				  zav = Math.floor(Math.random() * 100);
				  document.getElementById('zav1').src="demos/generation/audio/zds-"+zav+".png"
				  document.getElementById('zav2').src="demos/generation/audio-2/zds-"+zav+".png"
				}
    		</script>

			<div style="width:100%; text-align: center;">
			<table style="width:100%; text-align: center;">
					<td>
						 <p><button onclick="myFunctionZa()"> Sampling according to the Gaussian distribution prior of <span style="color:blue">\(\mathbf{z}^{(a)}\) </span></button></p>
						<img id="za1" src="demos/generation/audio/original.png" alt="audio-w"  width="400" />
						<img id="za2" src="demos/generation/audio-2/original.png" alt="audio-w"  width="400" />
					</td>
					<td>
						<p><button onclick="myFunctionZav()"> Sampling according to the Gaussian distribution prior of <span style="color:green">\(\mathbf{z}^{(av)}\) </span></button></p>
						<img id="zav1" src="demos/generation/audio/original.png" alt="audio-w"  width="400" />
						<img id="zav2" src="demos/generation/audio-2/original.png" alt="audio-w"  width="400" />
					</td>
			</table>
			</div>


			<!-- Interpolation in the static audiovisual latent space -->
			<span style="font-size: large;"><a name="latentspace"></a><strong>Interpolation in the static audiovisual latent space</strong></span>
			<hr>
			
			
			<div style="width:100%; text-align: center;">
			<table style="width:100%; text-align: center;">
					<td>
						<video controls autoplay  muted loop preload="auto" width="500">
						  <source src="demos/Video/emotions_interpolation.mp4" type="video/mp4">
						  <source src="demos/Video/emotions_interpolation.ogg" type="video/ogg">
						  Your browser does not support the video tag.
						</video>
					<p>Same identity, different emotions. </p>
					</td>
					
					<td>
						<video controls autoplay  muted loop preload="auto" width="500">
						  <source src="demos/Video/identity_interpolation.mp4" type="video/mp4">
						  <source src="demos/Video/identity_interpolation.ogg" type="video/ogg">
						  Your browser does not support the video tag.
						</video>
						<p> Same emotion, different identities.</p>
					</td>
			</table>
			</div>



			<div style="width:100%; text-align: center;">
			<table style="width:100%; text-align: center;">
				<td>
					<p> Two original visual sequences. (Scroll left) the visual sequence of a man; (Scroll right) the visual sequence of a woman;  </p>
					<img-comparison-slider value="10" hover=false>
						<img slot="second" src="demos/sliders/images/interpolation/identity-before.png" width="100%"/>
						<img slot="first" src="demos/sliders/images/interpolation/identity-after.png" width="100%" />
					</img-comparison-slider>
				</td>
				<td>
					<p> Two original visual sequences. (Scroll left) the visual sequence of a man; (Scroll right) the visual sequence of a woman;  </p>
					<img-comparison-slider value="10" hover=false>
						<img slot="second" src="demos/sliders/images/interpolation/emotion-before.png" width="100%"/>
						<img slot="first" src="demos/sliders/images/interpolation/emotion-after.png" width="100%" />
					</img-comparison-slider>
				</td>
			</table>
			</div>

			<!-- Interpolation in the static audiovisual latent space -->
			<span style="font-size: large;"><a name="latentspace"></a><strong>VISUALIZATION OF THE LATENT SPACES</strong></span>
			<div style="width:100%; text-align: center;">
			<iframe src="https://chart-studio.plotly.com/~sam-sad/21.embed" frameborder="0" width="960" height="960" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true">
			</iframe>
			</div>

		</div>
	</div>
</div>

</body>
</html>
